---
title: "EDS232 Lab 02: Communities"
author: "Julia Parish"
date: "2022/01/31"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

This machine learning analysis was completed as an assignment for my Masterâ€™s program course, Environmental Data Science 232: Machine Learning.


## Load in the data

```{r}
# load R packages
librarian::shelf(cluster, dplyr, DT, factoextra, ggplot2, ggvoronoi, scales, h2o, palmerpenguins, tibble, vegan, vegan3d)

# set seed for reproducible results
set.seed(42)

# load the dataset
data(package = 'palmerpenguins')

# load the dataset
data("iris")

# look at documentation in RStudio
if (interactive())
  help(penguins)

# show data table
datatable(penguins)

```

```{r}
# plot flipper length vs body mass, species naive
ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point()

# plot petal length vs width, color by species
legend_pos <- theme(
    legend.position = c(0.95, 0.05),
    legend.justification = c("right", "bottom"),
    legend.box.just = "right")

ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() +
  legend_pos
```

### Cluster `penguins` using `kmeans()`

```{r}
# remove na values from dataframe
penguins <- na.omit(penguins)

# cluster using kmeans
k <- 3  # number of clusters

penguins_k <- kmeans(
  penguins %>% 
    select(flipper_length_mm, body_mass_g), 
  centers = k)

# show cluster result
penguins_k

# compare clusters with species (which were not used to cluster)
table(penguins_k$cluster, penguins$species)
```

**Question**: How many observations could be considered "misclassified" if expecting flipper length and body mass to differentiate between species?


### Iris data
```{r}

# look at documentation in RStudio
if (interactive())
  help(iris)

# show data table
datatable(iris)
```

```{r}
# plot petal length vs width, species naive
ggplot(iris, aes(Petal.Length, Petal.Width)) +
  geom_point()

# plot petal length vs width, color by species
legend_pos <- theme(
    legend.position = c(0.95, 0.05),
    legend.justification = c("right", "bottom"),
    legend.box.just = "right")

ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) +
  geom_point() +
  legend_pos
```

### Cluster `iris` using `kmeans()`

```{r}
iris_k <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width), 
  centers = k)

# show cluster result
iris_k

# compare clusters with species (which were not used to cluster)
table(iris_k$cluster, iris$Species)
```

**Question**: How many observations could be considered "misclassified" if expecting petal length and width to differentiate between species?

```{r}
# extract cluster assignment per observation
Cluster = factor(iris_k$cluster)

ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster)) +
  geom_point() + 
  legend_pos
```

```{r, eval=F, echo=F}
# **Task**: Highlight the "misclassified" points in the plot. _Hints: To get just the points misclassified, you can use `iris_k$cluster != as.integer(iris$Species)`, which can feed as the second argument into `filter(iris)`. To add another set of points to the ggplot, use `+ geom_point()` with arguments for: `data` with the additional points, `pch` [point shape](https://www.r-bloggers.com/2021/06/r-plot-pch-symbols-different-point-shapes-in-r/) with `fill=NA` for transparency and outline `color="red"`._
obs_mis <- iris %>% 
  filter(iris_k$cluster != as.integer(iris$Species))

ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster)) +
  geom_point() + 
  legend_pos +
  geom_point(data = obs_mis, color="red", fill=NA, pch=21)
```

### Plot Voronoi diagram of clustered `iris`

This form of clustering assigns points to the cluster based on nearest centroid. You can see the breaks more clearly with a [Voronoi diagram](https://en.wikipedia.org/wiki/Voronoi_diagram).

```{r}
# define bounding box for geom_voronoi()
box <- tribble(
  ~Petal.Length, ~Petal.Width, ~group,
  1, 0.1, 1,
  1, 2.5, 1,
  7, 2.5, 1,
  7, 0.1, 1,
  1, 0.1, 1) %>% 
  data.frame()

# cluster using kmeans
k <- 3  # number of clusters

iris_k <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width), 
  centers = k)

# extract cluster assignment per observation
Cluster = factor(iris_k$cluster)

# extract cluster centers
ctrs <- as.data.frame(iris_k$centers) %>% 
  mutate(Cluster = factor(1:k))

# plot points with voronoi diagram showing nearest centroid
ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster)) +
  geom_point() + 
  legend_pos +
  geom_voronoi(
    data = ctrs, aes(fill=Cluster), color = NA, alpha=0.5, outline = box) + 
  geom_point(
    data = ctrs, pch=23, cex=2, fill="black")
```

**Task**: Show the Voronoi diagram for fewer (`k=2`) and more (`k=8`) clusters to see how assignment to cluster centroids work.

```{r}
# cluster using kmeans
k2 <- 2  # number of clusters

iris_k2 <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width), 
  centers = k2)

# extract cluster assignment per observation
Cluster2 = factor(iris_k2$cluster)

# extract cluster centers
ctrs2 <- as.data.frame(iris_k2$centers) %>% 
  mutate(Cluster2 = factor(1:k2))

# plot points with voronoi diagram showing nearest centroid
ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster2)) +
  geom_point() + 
  legend_pos +
  geom_voronoi(data = ctrs2, aes(fill=Cluster2), color = NA, alpha=0.5, outline = box) + 
  geom_point(data = ctrs2, pch=23, cex=2, fill="black") +
  labs(title = "Voronoi diagram for 2 clusters")
```

```{r}
# cluster using kmeans
k8 <- 8  # number of clusters

iris_k8 <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width), 
  centers = k8)

# extract cluster assignment per observation
Cluster8 = factor(iris_k8$cluster)

# extract cluster centers
ctrs8 <- as.data.frame(iris_k8$centers) %>% 
  mutate(Cluster8 = factor(1:k8))

# plot points with voronoi diagram showing nearest centroid
ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster8)) +
  geom_point() + 
  legend_pos +
  geom_voronoi(data = ctrs8, aes(fill=Cluster8), color = NA, alpha=0.5, outline = box) + 
  geom_point(data = ctrs8, pch=23, cex=2, fill="black") +
  labs(title = "Voronoi diagram for 2 clusters")
```

## Hierarchical Clustering

Next, cluster sites according to species composition. Use the `dune` dataset from the `vegan` R package.

### Load `dune` dataset

```{r}
# load dune dataset from package vegan
data("dune")

# show documentation on dataset if interactive
if (interactive())
  help(dune)
```

**Question**: What are the rows and columns composed of in the `dune` data frame?

Dune is a dataframe of 30 plant species at 20 sites. The columns are plant species and rows are cover class observations of those species. 

### Calculate Ecological Distances on `sites`

Before we calculate ecological distance between sites for `dune`, let's look at these metrics with a simpler dataset, like the example given in Chapter 8 by @kindtTreeDiversityAnalysis2005.

```{r}
sites <- tribble(
  ~site, ~sp1, ~sp2, ~sp3,
    "A",    1,    1,    0,
    "B",    5,    5,    0,
    "C",    0,    0,    1) %>% 
  column_to_rownames("site")
sites

sites_manhattan <- vegdist(sites, method="manhattan")
sites_manhattan

sites_euclidean <- vegdist(sites, method="euclidean")
sites_euclidean

sites_bray <- vegdist(sites, method="bray")
sites_bray
```

### Bray-Curtis Dissimilarity on `sites` 

Let's take a closer look at the [Bray-Curtis Dissimilarity](https://en.wikipedia.org/wiki/Bray%E2%80%93Curtis_dissimilarity) distance:

$$
B_{ij} = 1 - \frac{2C_{ij}}{S_i + S_j}
$$

- $B_{ij}$: Bray-Curtis dissimilarity value between sites $i$ and $j$. \
1 = completely dissimilar (no shared species); 0 = identical.

- $C_{ij}$: sum of the lesser counts $C$ for shared species common to both sites $i$ and $j$

- $S_{i OR j}$: sum of all species counts $S$ for the given site $i$ or $j$

So to calculate Bray-Curtis for the example `sites`: 

- $B_{AB} = 1 - \frac{2 * (1 + 1)}{2 + 10} = 1 - 4/12 = 1 - 1/3 = 0.667$

- $B_{AC} = 1 - \frac{2 * 0}{2 + 1} = 1$

- $B_{BC} = 1 - \frac{2 * 0}{10 + 1} = 1$


### Agglomerative hierarchical clustering on `dune` 

See text to accompany code: _HOMLR_ [21.3.1 Agglomerative hierarchical clustering](https://bradleyboehmke.github.io/HOML/hierarchical.html#agglomerative-hierarchical-clustering).

```{r}
# Dissimilarity matrix
d <- vegdist(dune, method="bray")
dim(d)
as.matrix(d)[1:5, 1:5]

# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete" )

# Dendrogram plot of hc1
plot(hc1, cex = 0.6, hang = -1)


# Compute agglomerative clustering with agnes
hc2 <- agnes(dune, method = "complete")

# Agglomerative coefficient
hc2$ac

# Dendrogram plot of hc2
plot(hc2, which.plot = 2)

# methods to assess
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# function to compute coefficient
ac <- function(x) {
  agnes(dune, method = x)$ac
}

# get agglomerative coefficient for each linkage method
purrr::map_dbl(m, ac)


# Compute ward linkage clustering with agnes
hc3 <- agnes(dune, method = "ward")

# Agglomerative coefficient
hc3$ac

# Dendrogram plot of hc3
plot(hc3, which.plot = 2)
```

### Divisive hierarchical clustering on `dune` 

See text to accompany code: _HOMLR_ [21.3.2 Divisive hierarchical clustering](https://bradleyboehmke.github.io/HOML/hierarchical.html#divisive-hierarchical-clustering).

```{r}
# compute divisive hierarchical clustering
hc4 <- diana(dune)

# Divise coefficient; amount of clustering structure found
hc4$dc
```

### Determining optimal clusters

See text to accompany code: _HOMLR_ [21.4 Determining optimal clusters](https://bradleyboehmke.github.io/HOML/hierarchical.html#determining-optimal-clusters).

```{r}
# Plot cluster results
p1 <- fviz_nbclust(dune, FUN = hcut, method = "wss",  k.max = 10) +
  ggtitle("(A) Elbow method")

p2 <- fviz_nbclust(dune, FUN = hcut, method = "silhouette", k.max = 10) +
  ggtitle("(B) Silhouette method")

p3 <- fviz_nbclust(dune, FUN = hcut, method = "gap_stat", k.max = 10) +
  ggtitle("(C) Gap statistic")

# Display plots side by side
gridExtra::grid.arrange(p1, p2, p3, nrow = 1)
```

### Working with dendrograms

See text to accompany code: _HOMLR_ [21.5 Working with dendrograms](https://bradleyboehmke.github.io/HOML/hierarchical.html#working-with-dendrograms).

```{r}
# Construct dendorgram for the Ames housing example
hc5 <- hclust(d, method = "ward.D2" )
dend_plot <- fviz_dend(hc5)
dend_data <- attr(dend_plot, "dendrogram")
dend_cuts <- cut(dend_data, h = 8)
fviz_dend(dend_cuts$lower[[2]])

# Ward's method
hc5 <- hclust(d, method = "ward.D2" )

# Cut tree into 4 groups
k = 4
sub_grp <- cutree(hc5, k = k)

# Number of members in each cluster
table(sub_grp)

# Plot full dendogram
fviz_dend(
  hc5,
  k = k,
  horiz = TRUE,
  rect = TRUE,
  rect_fill = TRUE,
  rect_border = "jco",
  k_colors = "jco")
```

# Section B. Ordination

Ordination 

## Principal Components Analysis (PCA)

### Prerequisites

```{r}
# get data
url <- "https://koalaverse.github.io/homlr/data/my_basket.csv"
my_basket <- readr::read_csv(url)
dim(my_basket)

my_basket
```

From [Section 1.4](https://bradleyboehmke.github.io/HOML/intro.html#data):

- `my_basket.csv`: Grocery items and quantities purchased. Each observation represents a single basket of goods that were purchased together.
  * Problem type: unsupervised basket analysis
  * response variable: NA
  * features: 42
  * observations: 2,000
  * objective: use attributes of each basket to identify common groupings of items purchased together.

### Performing PCA in R

```{r}
h2o.no_progress()  # turn off progress bars for brevity
h2o.init(max_mem_size = "5g")  # connect to H2O instance

# convert data to h2o object
my_basket.h2o <- as.h2o(my_basket)

# run PCA
my_pca <- h2o.prcomp(
  training_frame = my_basket.h2o,
  pca_method = "GramSVD",
  k = ncol(my_basket.h2o), 
  transform = "STANDARDIZE", 
  impute_missing = TRUE,
  max_runtime_secs = 1000)
my_pca

my_pca@model$eigenvectors %>% 
  as.data.frame() %>% 
  mutate(feature = row.names(.)) %>%
  ggplot(aes(pc1, reorder(feature, pc1))) +
  geom_point()

my_pca@model$eigenvectors %>% 
  as.data.frame() %>% 
  mutate(feature = row.names(.)) %>%
  ggplot(aes(pc1, pc2, label = feature)) +
  geom_text()
```

### Eigenvalue criterion

```{r}
# Compute eigenvalues
eigen <- my_pca@model$importance["Standard deviation", ] %>%
  as.vector() %>%
  .^2
  
# Sum of all eigenvalues equals number of variables
sum(eigen)
## [1] 42

# Find PCs where the sum of eigenvalues is greater than or equal to 1
which(eigen >= 1)

# Extract PVE and CVE
ve <- data.frame(
  PC  = my_pca@model$importance %>% seq_along(),
  PVE = my_pca@model$importance %>% .[2,] %>% unlist(),
  CVE = my_pca@model$importance %>% .[3,] %>% unlist())

# Plot PVE and CVE
ve %>%
  tidyr::gather(metric, variance_explained, -PC) %>%
  ggplot(aes(PC, variance_explained)) +
  geom_point() +
  facet_wrap(~ metric, ncol = 1, scales = "free")

# How many PCs required to explain at least 75% of total variability
min(which(ve$CVE >= 0.75))

# Screee plot criterion
data.frame(
  PC  = my_pca@model$importance %>% seq_along,
  PVE = my_pca@model$importance %>% .[2,] %>% unlist()) %>%
  ggplot(aes(PC, PVE, group = 1, label = PC)) +
  geom_point() +
  geom_line() +
  geom_text(nudge_y = -.002)
```


## Non-metric MultiDimensional Scaling (NMDS)

### Unconstrained Ordination on Species

```{r}
# vegetation and environment in lichen pastures from Vare et al (1995)
data("varespec") # species
data("varechem") # chemistry

varespec %>% tibble()
vare.dis <- vegdist(varespec)
vare.mds0 <- monoMDS(vare.dis)
stressplot(vare.mds0)

ordiplot(vare.mds0, type = "t")

vare.mds <- metaMDS(varespec, trace = FALSE)
vare.mds

plot(vare.mds, type = "t")
```

### Overlay with Environment

See supporting text in [vegantutor.pdf](https://github.com/bbest/eds232-ml/raw/main/files/vegantutor.pdf): 
  * 3 Environmental interpretation
  * 3.1 Vector fitting
  * 3.2 Surface fitting

```{r}
ef <- envfit(vare.mds, varechem, permu = 999)
ef

plot(vare.mds, display = "sites")
plot(ef, p.max = 0.05)


ef <- envfit(vare.mds ~ Al + Ca, data = varechem)
plot(vare.mds, display = "sites")
plot(ef)

tmp <- with(varechem, ordisurf(vare.mds, Al, add = TRUE))
ordisurf(vare.mds ~ Ca, data=varechem, add = TRUE, col = "green4")
```


### Constrained Ordination on Species and Environment
  
Technically, this uses another technique `cca`, or canonical correspondence analysis.

```{r}
# ordinate on species constrained by three soil elements
vare.cca <- cca(varespec ~ Al + P + K, varechem)
vare.cca

# plot ordination
plot(vare.cca)

# plot 3 dimensions
ordiplot3d(vare.cca, type = "h")
  
if (interactive()){
  ordirgl(vare.cca)
}
```







